{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from functions2 import *\n",
    "from parameters import *\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import lasso_path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Data (data-frame)\" )\n",
    "filename = \"raw/data_ml.csv\"\n",
    "LOG( f\"  Reading {filename} [20 seconds]\" )\n",
    "d = pd.read_csv(filename)\n",
    "d['date'] = pd.to_datetime( d['date'] )\n",
    "\n",
    "predictors = list( signs.keys() )\n",
    "target = 'R1M_Usd'\n",
    "\n",
    "LOG( \"Data (list of matrices)\" )\n",
    "LOG( \"  Reading data/data_ml.pickle\" )\n",
    "dd = load( \"data/data_ml.pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear3(torch.nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(Linear3,self).__init__()\n",
    "        self.linear = torch.nn.Linear(k,1)\n",
    "    def forward(self,xs):\n",
    "        x, universe = xs\n",
    "        # x is n×l×k; the linear layer is applied on the last dimension\n",
    "        y = self.linear(x)   # n×l×1\n",
    "        p = y.exp()             # Use a softplus instead of an exponential?\n",
    "        p = p * universe\n",
    "        p = p[:,:,0]         #  n×l\n",
    "        p = p / ( 1e-16 + p.sum(axis=0) )  # portolio weights: positive, sum up to 1 for each date\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batches\n",
    "To make the model more robust, we train it on \"mini-batches\", defined by a random subset of stocks, and a time interval (contiguous dates).\n",
    "These are not real mini-batches, because the loss function is not a sum over the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"[LONG] 30 minutes for 10,000 epochs\" )\n",
    "\n",
    "x, y, universe = get_data_3(date=DATE1, signs=signs)\n",
    "\n",
    "universe = universe.reshape( y.shape[0], y.shape[1], 1 )\n",
    "y = y.reshape( y.shape[0], y.shape[1], 1 )\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "universe = torch.tensor(universe, dtype=torch.float32)\n",
    "\n",
    "model = Linear3(x.shape[2])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "N = 10_000\n",
    "IRs = np.nan * np.zeros(N)\n",
    "pbar = tqdm(range(N))\n",
    "for t in pbar:\n",
    "    \n",
    "    x.shape  # id×date×feature\n",
    "    ## Take half the stocks at random\n",
    "    i = np.random.choice( x.shape[0], x.shape[0] // 2, replace=False ) \n",
    "    ## Take a 3-year period, at random\n",
    "    j = np.random.choice( x.shape[1] - 36 )\n",
    "    j = np.arange( j, j+36 )\n",
    "    \n",
    "    w = model( (x[i,:,:][:,j,:], universe[i,:,:][:,j,:]) )\n",
    "    ratio_returns = w * y[i,:,:][:,j,:][:,:,0].expm1()     # y already contains the forward returns\n",
    "    ratio_returns = ratio_returns.sum(axis=0)\n",
    "    log_returns = ratio_returns.log1p()\n",
    "    IR = log_returns.mean() / log_returns.std()\n",
    "    loss = -IR\n",
    "    IRs[t] = IR.item()\n",
    "    pbar.set_description( f\"IR={np.nanmean(IRs):.3f}\" )\n",
    "    if not np.isfinite( loss.item() ):\n",
    "        LOG( f\"{t} PROBLEM\" )\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "LOG( \"DONE\" )\n",
    "\n",
    "## Add the final IR, on the whole sample\n",
    "w = model( (x,universe) )\n",
    "ratio_returns = w * y[:,:,0].expm1()     # y already contains the forward returns\n",
    "ratio_returns = ratio_returns.sum(axis=0)\n",
    "log_returns = ratio_returns.log1p()\n",
    "IR = log_returns.mean() / log_returns.std()\n",
    "IR = IR.item()\n",
    "\n",
    "## The performance we recorded is very noisy: it is on different periods...\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter( 1+np.arange(len(IRs)), IRs )\n",
    "r = lowess( IRs, 1+np.arange(len(IRs)) )\n",
    "ax.plot( r[:,0], r[:,1], color = 'black', linewidth=5 )\n",
    "ax.scatter( 1+len(IRs), IR, color = 'tab:orange', marker='x', s=200, linewidth=5)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"IR\")\n",
    "ax.set_xscale('log')\n",
    "fig.savefig(\"plots/model3b_linear_IR_minibatches_loss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wealth curves\n",
    "\n",
    "x, y, universe = get_data_3(all=True, signs=signs)\n",
    "universe = universe.reshape( y.shape[0], y.shape[1], 1 )\n",
    "y = y.reshape( y.shape[0], y.shape[1], 1 )\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "universe = torch.tensor(universe, dtype=torch.float32)\n",
    "\n",
    "signal = model( (x,universe) ).detach().numpy()\n",
    "\n",
    "trailing_log_returns = LAG( np.log1p( dd[ 'R1M_Usd' ] ) )\n",
    "y = trailing_log_returns.copy()\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "assert signal.shape == y.shape\n",
    "signal = pd.DataFrame( signal, index = y.index, columns = y.columns )\n",
    "\n",
    "res = signal_backtest(signal, y, date=DATE1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(6):\n",
    "    ax.plot( res['dates'], res['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.axvline( pd.to_datetime(DATE1), color='black', linewidth=1 )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Maximizing the IR (signal, mini-batches)')\n",
    "ax.text(0.02, .97, f\"μ={100*res['out-of-sample'].iloc[5,:]['CAGR']:.1f}%\",                  horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .90, f\"σ={100*res['out-of-sample'].iloc[5,:]['Annualized Volatility']:.1f}%\", horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .83, f\"IR={res['out-of-sample'].iloc[5,:]['Information Ratio']:.2f}\",         horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "fig.savefig(\"plots/model3b_linear_IR_minibatches_wealth.pdf\")\n",
    "plt.show()\n",
    "\n",
    "res['out-of-sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest the strategy actually learned\n",
    "\n",
    "r = compute_portfolio_returns( signal, np.expm1(trailing_log_returns) ) \n",
    "p = np.exp(cumsum_na(r))               # Log-price = cummulated log-returns\n",
    "p = replace_last_leading_NaN_with_1(p) # \"cumsum\" is not the exact inverse of \"diff\" -- it discards the first value, 1: put it back\n",
    "s = analyze_returns( r[ r.index > DATE1 ], as_df = True )\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(5):\n",
    "    ax.plot( res['dates'], res['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.plot( p.index, p, color='black' )\n",
    "ax.axvline( pd.to_datetime(DATE1), color='black', linewidth=1 )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Maximizing the IR (weights, mini-batches)')\n",
    "ax.text(0.02, .97, f\"μ={100*s.iloc[0,:]['CAGR']:.1f}%\",                  horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .90, f\"σ={100*s.iloc[0,:]['Annualized Volatility']:.1f}%\", horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .83, f\"IR={s.iloc[0,:]['Information Ratio']:.2f}\",         horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "fig.savefig(\"plots/model3b_linear_IR_minibatches_wealth_weights.pdf\")\n",
    "plt.show()\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Done.\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
