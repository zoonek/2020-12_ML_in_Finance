@article{arnott_fundamental_2005,
	title = {Fundamental {Indexation}},
	volume = {61},
	issn = {0015-198X, 1938-3312},
	url = {https://www.tandfonline.com/doi/full/10.2469/faj.v61.n2.2718},
	doi = {10.2469/faj.v61.n2.2718},
	number = {2},
	urldate = {2020-10-24},
	journal = {Financial Analysts Journal},
	author = {Arnott, Robert D. and Hsu, Jason and Moore, Philip},
	month = mar,
	year = {2005},
	pages = {83--99}
}

@book{fernholz_stochastic_2002,
	address = {New York, NY},
	title = {Stochastic {Portfolio} {Theory}},
	isbn = {9781441929877 9781475736991},
	url = {http://link.springer.com/10.1007/978-1-4757-3699-1},
	urldate = {2020-10-24},
	publisher = {Springer New York},
	author = {Fernholz, E. Robert},
	year = {2002},
	doi = {10.1007/978-1-4757-3699-1}
}

@article{vervuurt_topics_2015,
	title = {Topics in {Stochastic} {Portfolio} {Theory}},
	url = {http://arxiv.org/abs/1504.02988},
	abstract = {This is an overview of the area of Stochastic Portfolio Theory, and can be seen as an updated and extended version of the survey paper by Fernholz and Karatzas (Handbook of Numerical Analysis Vol.15:89-167, 2009).},
	urldate = {2020-10-24},
	journal = {arXiv:1504.02988 [math, q-fin]},
	author = {Vervuurt, Alexander},
	month = apr,
	year = {2015},
	OPTnote = {arXiv: 1504.02988},
	keywords = {Quantitative Finance - Mathematical Finance, Mathematics - Probability, Quantitative Finance - Portfolio Management, 60-02, 91-01}
}

@techreport{fernholz_stock_2005,
	title = {Stock market diversity},
	url = {http://www.q-group.org/wp-content/uploads/2014/01/Stock-Market_Diversity.pdf},
	institution = {Intech},
	author = {Fernholz, Robert},
	year = {2005}
}

@article{fernholz_diversity-weighted_1998,
	title = {Diversity-{Weighted} {Indexing}},
	volume = {24},
	issn = {0095-4918, 2168-8656},
	url = {http://jpm.pm-research.com/lookup/doi/10.3905/jpm.24.2.74},
	doi = {10.3905/jpm.24.2.74},
	number = {2},
	urldate = {2020-10-24},
	journal = {The Journal of Portfolio Management},
	author = {Fernholz, Robert and Garvy, Robert and Hannon, John},
	month = jan,
	year = {1998},
	pages = {74--82}
}

@article{samo_stochastic_2016,
	title = {Stochastic {Portfolio} {Theory}: {A} {Machine} {Learning} {Perspective}},
	shorttitle = {Stochastic {Portfolio} {Theory}},
	url = {http://arxiv.org/abs/1605.02654},
	abstract = {In this paper we propose a novel application of Gaussian processes (GPs) to financial asset allocation. Our approach is deeply rooted in Stochastic Portfolio Theory (SPT), a stochastic analysis framework introduced by Robert Fernholz that aims at flexibly analysing the performance of certain investment strategies in stock markets relative to benchmark indices. In particular, SPT has exhibited some investment strategies based on company sizes that, under realistic assumptions, outperform benchmark indices with probability 1 over certain time horizons. Galvanised by this result, we consider the inverse problem that consists of learning (from historical data) an optimal investment strategy based on any given set of trading characteristics, and using a user-specified optimality criterion that may go beyond outperforming a benchmark index. Although this inverse problem is of the utmost interest to investment management practitioners, it can hardly be tackled using the SPT framework. We show that our machine learning approach learns investment strategies that considerably outperform existing SPT strategies in the US stock market.},
	urldate = {2020-10-24},
	journal = {arXiv:1605.02654 [q-fin, stat]},
	author = {Samo, Yves-Laurent Kom and Vervuurt, Alexander},
	month = may,
	year = {2016},
	OPTnote = {arXiv: 1605.02654},
	keywords = {Quantitative Finance - Portfolio Management, Quantitative Finance - Mathematical Finance, Statistics - Machine Learning, 60G15, 60H30, 91G10}
}

@techreport{zoonekynd_end--end_2017,
	title = {End-to-end portfolio construction},
	institution = {Deutsche Bank},
	author = {Zoonekynd, Vincent and LeBinh, Khoi and Tang, Jiazi and Sambatur, Hemant and Lai, Elita},
	year = {2017}
}

@article{you_deep_2017,
	title = {Deep {Lattice} {Networks} and {Partial} {Monotonic} {Functions}},
	url = {http://arxiv.org/abs/1709.06680},
	abstract = {We propose learning deep models that are monotonic with respect to a user-specified set of inputs by alternating layers of linear embeddings, ensembles of lattices, and calibrators (piecewise linear functions), with appropriate constraints for monotonicity, and jointly training the resulting network. We implement the layers and projections with new computational graph nodes in TensorFlow and use the ADAM optimizer and batched stochastic gradients. Experiments on benchmark and real-world datasets show that six-layer monotonic deep lattice networks achieve state-of-the art performance for classification and regression with monotonicity guarantees.},
	urldate = {2020-10-24},
	journal = {arXiv:1709.06680 [cs, stat]},
	author = {You, Seungil and Ding, David and Canini, Kevin and Pfeifer, Jan and Gupta, Maya},
	month = sep,
	year = {2017},
	OPTnote = {arXiv: 1709.06680},
	keywords = {Statistics - Machine Learning, Computer Science - Machine Learning}
}

@article{agrawal_differentiable_2019,
	title = {Differentiable {Convex} {Optimization} {Layers}},
	url = {http://arxiv.org/abs/1910.12430},
	urldate = {2020-10-24},
	journal = {arXiv:1910.12430 [cs, math, stat]},
	author = {Agrawal, Akshay and Amos, Brandon and Barratt, Shane and Boyd, Stephen and Diamond, Steven and Kolter, Zico},
	month = oct,
	year = {2019},
	OPTnote = {arXiv: 1910.12430}
}

@article{zhang_deep_2020,
	title = {Deep {Learning} for {Portfolio} {Optimization}},
	issn = {2405-9188},
	url = {https://jfds.pm-research.com/content/early/2020/08/26/jfds.2020.1.042},
	doi = {10.3905/jfds.2020.1.042},
	urldate = {2020-10-24},
	journal = {The Journal of Financial Data Science},
	author = {Zhang, Zihao and Zohren, Stefan and Roberts, Stephen},
	year = {2020}
}

@book{coqueret_machine_2020,
	edition = {1},
	title = {Machine {Learning} for {Factor} {Investing}: {R} {Version}},
	isbn = {9781003034858},
	shorttitle = {Machine {Learning} for {Factor} {Investing}},
	url = {http://www.mlfactor.com/},
	urldate = {2020-10-25},
	publisher = {Chapman and Hall/CRC},
	author = {Coqueret, Guillaume and Guida, Tony},
	month = aug,
	year = {2020},
	doi = {10.1201/9781003034858}
}

@article{liu_certified_2020,
	title = {Certified {Monotonic} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2011.10219},
	abstract = {Learning monotonic models with respect to a subset of the inputs is a desirable feature to effectively address the fairness, interpretability, and generalization issues in practice. Existing methods for learning monotonic neural networks either require specifically designed model structures to ensure monotonicity, which can be too restrictive/complicated, or enforce monotonicity by adjusting the learning process, which cannot provably guarantee the learned model is monotonic on selected features. In this work, we propose to certify the monotonicity of the general piece-wise linear neural networks by solving a mixed integer linear programming problem.This provides a new general approach for learning monotonic neural networks with arbitrary model structures. Our method allows us to train neural networks with heuristic monotonicity regularizations, and we can gradually increase the regularization magnitude until the learned network is certified monotonic. Compared to prior works, our approach does not require human-designed constraints on the weight space and also yields more accurate approximation. Empirical studies on various datasets demonstrate the efficiency of our approach over the state-of-the-art methods, such as Deep Lattice Networks.},
	urldate = {2021-03-07},
	journal = {arXiv:2011.10219 [cs]},
	author = {Liu, Xingchao and Han, Xing and Zhang, Na and Liu, Qiang},
	month = nov,
	year = {2020},
	OPTnote = {arXiv: 2011.10219},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
}


@article{dixon_short_2020,
	title = {Short {Communication}: {Deep} {Fundamental} {Factor} {Models}},
	volume = {11},
	issn = {1945-497X},
	shorttitle = {Short {Communication}},
	url = {https://epubs.siam.org/doi/10.1137/20M1330518},
	doi = {10.1137/20M1330518},
	language = {en},
	number = {3},
	urldate = {2021-03-25},
	journal = {SIAM Journal on Financial Mathematics},
	author = {Dixon, Matthew and Polson, Nick},
	month = jan,
	year = {2020},
	pages = {SC--26--SC--37},
}

@techreport{sak_exploring_2021,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Exploring the {Factor} {Zoo} {With} a {Machine}-{Learning} {Portfolio}},
	url = {https://papers.ssrn.com/abstract=3202277},
	abstract = {Over the years, top journals have published hundreds of characteristics to explain stock return, but many have lost significance. What fundamentally affects the time-varying significance of characteristics? We combine machine-learning (ML) and portfolio analysis to uncover patterns in significant characteristics. We train ML models on 106 characteristics to predict stock returns. From out-of-sample ML portfolio analysis, we reverse-engineer important characteristics that ML models uncover, which are unobservable. The ML portfolioâ€™s dominant characteristics rotate between proxies for investor arbitrage constraint and firm financial constraint. We show that the credit cycle could fundamentally explain cross-sectional stock return over time.},
	language = {en},
	number = {ID 3202277},
	urldate = {2021-03-25},
	institution = {Social Science Research Network},
	author = {Sak, Halis and Huang, Tao and Chng, Michael},
	month = jan,
	year = {2021},
	keywords = {Machine Learning, Characteristics, Return Predictability, Portfolio Evaluation},
}

@article{nakagawa_deep_2018,
	title = {Deep {Factor} {Model}},
	url = {http://arxiv.org/abs/1810.01278},
	abstract = {We propose to represent a return model and risk model in a unified manner with deep learning, which is a representative model that can express a nonlinear relationship. Although deep learning performs quite well, it has significant disadvantages such as a lack of transparency and limitations to the interpretability of the prediction. This is prone to practical problems in terms of accountability. Thus, we construct a multifactor model by using interpretable deep learning. We implement deep learning as a return model to predict stock returns with various factors. Then, we present the application of layer-wise relevance propagation (LRP) to decompose attributes of the predicted return as a risk model. By applying LRP to an individual stock or a portfolio basis, we can determine which factor contributes to prediction. We call this model a deep factor model. We then perform an empirical analysis on the Japanese stock market and show that our deep factor model has better predictive capability than the traditional linear model or other machine learning methods. In addition , we illustrate which factor contributes to prediction.},
	urldate = {2021-03-25},
	journal = {arXiv:1810.01278 [q-fin]},
	author = {Nakagawa, Kei and Uchida, Takumi and Aoshima, Tomohisa},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.01278},
	keywords = {Quantitative Finance - Statistical Finance},
}

@article{nakagawa_deep_2019,
	title = {Deep {Recurrent} {Factor} {Model}: {Interpretable} {Non}-{Linear} and {Time}-{Varying} {Multi}-{Factor} {Model}},
	shorttitle = {Deep {Recurrent} {Factor} {Model}},
	url = {http://arxiv.org/abs/1901.11493},
	abstract = {A linear multi-factor model is one of the most important tools in equity portfolio management. The linear multi-factor models are widely used because they can be easily interpreted. However, financial markets are not linear and their accuracy is limited. Recently, deep learning methods were proposed to predict stock return in terms of the multi-factor model. Although these methods perform quite well, they have significant disadvantages such as a lack of transparency and limitations in the interpretability of the prediction. It is thus difficult for institutional investors to use black-box-type machine learning techniques in actual investment practice because they should show accountability to their customers. Consequently, the solution we propose is based on LSTM with LRP. Specifically, we extend the linear multi-factor model to be non-linear and time-varying with LSTM. Then, we approximate and linearize the learned LSTM models by LRP. We call this LSTM+LRP model a deep recurrent factor model. Finally, we perform an empirical analysis of the Japanese stock market and show that our recurrent model has better predictive capability than the traditional linear model and fully-connected deep learning methods.},
	urldate = {2021-03-25},
	journal = {arXiv:1901.11493 [cs, q-fin]},
	author = {Nakagawa, Kei and Ito, Tomoki and Abe, Masaya and Izumi, Kiyoshi},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.11493},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance},
}
