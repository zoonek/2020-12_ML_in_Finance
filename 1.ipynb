{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from parameters import *\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import lasso_path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data, as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Data (data-frame)\" )\n",
    "filename = \"raw/data_ml.csv\"\n",
    "LOG( f\"Reading {filename} [20 seconds]\" )\n",
    "d = pd.read_csv(filename)\n",
    "d['date'] = pd.to_datetime( d['date'] )\n",
    "\n",
    "predictors = list( signs.keys() )\n",
    "target = 'R1M_Usd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than a data-frame, it is often easier to have a list of matrices, one per variable, \n",
    "with one row per stock and one column per date: we can easily combine them or apply some function to each row, or each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Data (list of matrices)\" )\n",
    "LOG( \"Read data/data_ml.pickle\" )\n",
    "dd = load( \"data/data_ml.pickle\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single signals\n",
    "For any of the input variables, we can divide the universe into quintiles, long the top quintile, and short the bottom quintile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Backtest a single signal\" )\n",
    "trailing_log_returns = LAG( np.log1p( dd[ 'R1M_Usd' ] ) )\n",
    "y = trailing_log_returns.copy()\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "signal = predictors[0]\n",
    "LOG( f\"  {signal}\" )\n",
    "x = dd[signal].copy() * signs[signal]\n",
    "x.fillna(.5, inplace=True)  ## Replace missing values with the median (0.5, since the predictors are uniform)\n",
    "x = np.where( dd['universe'], 1, np.nan ) * x   # Only invest in stocks in the universe\n",
    "r = signal_backtest(x, y, date = DATE1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(6):\n",
    "    ax.plot( r['dates'], r['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title(signal if signs[signal]>=0 else f\"- {signal}\")\n",
    "plt.show()\n",
    "\n",
    "r['performance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso\n",
    "We try to forecast the 1-month forward return from all the input variables. \n",
    "\n",
    "As we let the scale of the $L^1$ penalty vary, we have a family of increasingly complex models, from the intercept-only one, to the (unpenalized) least-squares model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Training data\" )\n",
    "i = np.array([ str(u) < DATE1 for u in d['date'] ]) \n",
    "train = d[i].copy()\n",
    "x = train[ predictors ]\n",
    "y = np.log1p(train[ target ])\n",
    "\n",
    "LOG( \"Clean the data\" )\n",
    "i = np.isfinite(y)\n",
    "x = x[i]\n",
    "y = y[i]\n",
    "\n",
    "x = x.fillna(.5)\n",
    "\n",
    "LOG( \"Lasso\" )\n",
    "alphas, coef, _ = lasso_path( X = x, y = y, max_iter = 10_000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailing_log_returns = LAG( np.log1p( dd[ 'R1M_Usd' ] ) )\n",
    "y = trailing_log_returns.copy()\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "LOG( \"Loop: backtests of the lasso models [10 minutes]\" )\n",
    "res = {}\n",
    "for j in tqdm(range(len(alphas))):\n",
    "    signal = np.zeros( shape = dd[ list(dd.keys())[0] ].shape )\n",
    "    for i,predictor in enumerate(predictors):\n",
    "        signal += coef[i,j] * dd[predictor].fillna(.5)\n",
    "    signal = np.where( dd['universe'], 1, np.nan ) * signal\n",
    "    r = signal_backtest(signal, y, date=DATE1)\n",
    "    r['performance'  ]['alpha'] = alphas[j]\n",
    "    r['in-sample'    ]['alpha'] = alphas[j]\n",
    "    r['out-of-sample']['alpha'] = alphas[j]\n",
    "    r['performance'  ]['period'] = 'all'\n",
    "    r['in-sample'    ]['period'] = 'in-sample'\n",
    "    r['out-of-sample']['period'] = 'out-of-sample'    \n",
    "    res[ f\"{alphas[j]} all\" ] = r['performance']\n",
    "    res[ f\"{alphas[j]} in\"  ] = r['in-sample']\n",
    "    res[ f\"{alphas[j]} out\" ] = r['out-of-sample']\n",
    "    \n",
    "    if j == 20:\n",
    "        # Wealth curves\n",
    "        fig, ax = plt.subplots()\n",
    "        for i in range(6):\n",
    "            ax.plot( r['dates'], r['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title( f\"alpha={alphas[j]:5.3}\")\n",
    "        plt.show()\n",
    "        \n",
    "res = pd.concat( res.values() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the in-sample performance to increase, and the out-of-sample performance to increase and then decrease -- \n",
    "this is not what we see here: the out-of-sample performance does not decrease, and a linear model performs extremely well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = ( res['portfolio'] == 'LS' ) & ( res['period'] == 'in-sample' )\n",
    "i2 = ( res['portfolio'] == 'LS' ) & ( res['period'] == 'out-of-sample' )\n",
    "i3 = ( res['portfolio'] == 'LS' ) & ( res['period'] == 'all' )\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "for j,key in enumerate(['Information Ratio', 'CAGR', 'Annualized Volatility']):\n",
    "    ax = axs[j]\n",
    "    ax.plot( res[i1]['alpha'], res[i1][key], label = \"in-sample\" )\n",
    "    ax.plot( res[i2]['alpha'], res[i2][key], label = \"out-of-sample\" )\n",
    "    #ax.plot( res[i3]['alpha'], res[i3][key], label = \"all\" )\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.set_xscale('log')\n",
    "    ax.invert_xaxis()\n",
    "    ax.set_title(key)\n",
    "    ax.legend()\n",
    "plt.show()\n",
    "\n",
    "number_of_predictors = ( coef != 0 ).sum(axis=0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot( alphas, number_of_predictors )\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_xscale('log')\n",
    "ax.invert_xaxis()\n",
    "ax.set_title('Number of predictors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the linear models, to prevent it from overfitting the data, \n",
    "and to ensure the model remains interpretable, we can add constraints on the signs of the coefficients of the regression.\n",
    "Indeed we know in advance whether each predictor has a positive or negative impact on future returns:\n",
    "for instance, volatility has a negative impact, while earnings yield has a positive impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import lsq_linear\n",
    "\n",
    "LOG( \"Training data\" )\n",
    "i = np.array([ str(u) < DATE1 for u in d['date'] ]) \n",
    "train = d[i].copy()\n",
    "x = train[ predictors ]\n",
    "y = np.log1p(train[ target ])\n",
    "\n",
    "LOG( \"Clean the data\" )\n",
    "i = np.isfinite(y)\n",
    "x = x[i]\n",
    "y = y[i]\n",
    "\n",
    "x = x.fillna(.5)\n",
    "\n",
    "LOG( \"Fit the model\" )\n",
    "r = lsq_linear(\n",
    "    x, y,\n",
    "    (\n",
    "        [ 0      if signs[u] > 0 else -np.inf for u in predictors ],\n",
    "        [ np.inf if signs[u] > 0 else 0       for u in predictors ],\n",
    "    )\n",
    ")\n",
    "\n",
    "# It is not supposed to be that sparse: usually, 2/3 of the coefficients are non-zero...\n",
    "w = np.round( 1e6 * r.x )\n",
    "{ p: w[i] for i,p in enumerate(predictors) if w[i] != 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Data for the backtest\" )\n",
    "trailing_log_returns = LAG( np.log1p( dd[ 'R1M_Usd' ] ) )\n",
    "y = trailing_log_returns.copy()\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "signal = np.zeros( shape = dd[ list(dd.keys())[0] ].shape )\n",
    "for i,predictor in enumerate(predictors):\n",
    "    signal += r.x[i] * dd[predictor].fillna(.5)\n",
    "    #signal += r_rev.x[i] * dd[predictor].fillna(.5)\n",
    "    #signal += r_ols.x[i] * dd[predictor].fillna(.5)\n",
    "signal = np.where( dd['universe'], 1, np.nan ) * signal\n",
    "res = signal_backtest(signal, y, date=DATE1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(6):\n",
    "    ax.plot( res['dates'], res['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Constrained regression')\n",
    "plt.show()\n",
    "\n",
    "res['out-of-sample']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning: linear model\n",
    "This is equivalent to the models above, but implemented with a neural network.\n",
    "* Linear model\n",
    "* Add mini-batches\n",
    "* Add sign constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning: lattice networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning: optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
