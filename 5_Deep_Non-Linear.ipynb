{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from functions2 import *\n",
    "from parameters import *\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import lasso_path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Data (data-frame)\" )\n",
    "filename = \"raw/data_ml.csv\"\n",
    "LOG( f\"  Reading {filename} [20 seconds]\" )\n",
    "d = pd.read_csv(filename)\n",
    "d['date'] = pd.to_datetime( d['date'] )\n",
    "\n",
    "predictors = list( signs.keys() )\n",
    "\n",
    "LOG( \"Data (list of matrices)\" )\n",
    "LOG( \"  Reading data/data_ml.pickle\" )\n",
    "dd = load( \"data/data_ml.pickle\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning: nonlinear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinear6(torch.nn.Module):\n",
    "    def __init__(self,k):\n",
    "        super(NonLinear6,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(k,16)\n",
    "        self.fc2 = torch.nn.Linear(16,4)\n",
    "        self.fc3 = torch.nn.Linear(4,1)\n",
    "    def forward(self,xs):\n",
    "        x, universe = xs\n",
    "        # x is n×l×k; the linear layer is applied on the last dimension\n",
    "        y = self.fc1(x); y = F.relu(y)\n",
    "        y = self.fc2(y); y = F.relu(y)\n",
    "        y = self.fc3(y)      # n×l×1\n",
    "        p = y.exp()          # Use a softplus instead of an exponential?\n",
    "        p = p * universe\n",
    "        p = p[:,:,0]         #  n×l\n",
    "        p = p / ( 1e-16 + p.sum(axis=0) )  # portolio weights: positive, sum up to 1 for each date\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"[LONG] 25 minutes for 10,000 epochs\" )\n",
    "\n",
    "x, y, universe = get_data_3(date=DATE1, signs=signs, target=target)\n",
    "\n",
    "universe = universe.reshape( y.shape[0], y.shape[1], 1 )\n",
    "y = y.reshape( y.shape[0], y.shape[1], 1 )\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "universe = torch.tensor(universe, dtype=torch.float32)\n",
    "\n",
    "model = NonLinear6(x.shape[2])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "N = 100\n",
    "IRs = np.nan * np.zeros(N)\n",
    "pbar = tqdm(range(N))\n",
    "for t in pbar:\n",
    "    \n",
    "    x.shape  # id×date×feature\n",
    "    ## Take half the stocks at random\n",
    "    i = np.random.choice( x.shape[0], x.shape[0] // 2, replace=False ) \n",
    "    ## Take a 3-year period, at random\n",
    "    j = np.random.choice( x.shape[1] - 36 )\n",
    "    j = np.arange( j, j+36 )\n",
    "    \n",
    "    w = model( (x[i,:,:][:,j,:], universe[i,:,:][:,j,:]) )\n",
    "    ratio_returns = w * y[i,:,:][:,j,:][:,:,0].expm1()     # y already contains the forward returns\n",
    "    ratio_returns = ratio_returns.sum(axis=0)\n",
    "    log_returns = ratio_returns.log1p()\n",
    "    IR = log_returns.mean() / log_returns.std()\n",
    "    loss = -IR\n",
    "    IRs[t] = IR.item()\n",
    "    pbar.set_description( f\"IR={np.nanmean(IRs):.3f}\" )\n",
    "    if not np.isfinite( loss.item() ):\n",
    "        LOG( f\"{t} PROBLEM\" )\n",
    "        break\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "LOG( \"DONE\" )\n",
    "\n",
    "## Add the final IR, on the whole sample\n",
    "w = model( (x,universe) )\n",
    "ratio_returns = w * y[:,:,0].expm1()     # y already contains the forward returns\n",
    "ratio_returns = ratio_returns.sum(axis=0)\n",
    "log_returns = ratio_returns.log1p()\n",
    "IR = log_returns.mean() / log_returns.std()\n",
    "IR = IR.item()\n",
    "\n",
    "## The performance we recorded is very noisy: it is on different periods...\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter( 1+np.arange(len(IRs)), IRs )\n",
    "r = lowess( IRs, 1+np.arange(len(IRs)) )\n",
    "ax.plot( r[:,0], r[:,1], color = 'black', linewidth=5 )\n",
    "ax.scatter( 1+len(IRs), IR, color = 'tab:orange', marker='x', s=200, linewidth=5)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"IR\")\n",
    "ax.set_xscale('log')\n",
    "fig.savefig(\"plots/model6_nonlinear_IR_loss.pdf\")\n",
    "plt.show()\n",
    "\n",
    "pd.Series(IRs).to_csv(\"results/model6_nonlinear_IR_loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wealth curves\n",
    "##\n",
    "## This is not the strategy actually learned, but the quintile portfolios from the score.\n",
    "## The strategy learned provided actual weights.\n",
    "## \n",
    "\n",
    "x, y, universe = get_data_3(all=True, signs=signs, target='R1M_Usd')\n",
    "universe = universe.reshape( y.shape[0], y.shape[1], 1 )\n",
    "y = y.reshape( y.shape[0], y.shape[1], 1 )\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "universe = torch.tensor(universe, dtype=torch.float32)\n",
    "\n",
    "signal = model( (x,universe) ).detach().numpy()\n",
    "\n",
    "trailing_log_returns = LAG( np.log1p( dd[ 'R1M_Usd' ] ) )\n",
    "y = trailing_log_returns.copy()\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "assert signal.shape == y.shape\n",
    "signal = pd.DataFrame( signal, index = y.index, columns = y.columns )\n",
    "\n",
    "res = signal_backtest(signal, y, date=DATE1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(6):\n",
    "    ax.plot( res['dates'], res['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.axvline( pd.to_datetime(DATE1), color='black', linewidth=1 )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Maximizing the IR (non-linear, signal)')\n",
    "ax.text(0.02, .97, f\"μ={100*res['out-of-sample'].iloc[5,:]['CAGR']:.1f}%\",                  horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .90, f\"σ={100*res['out-of-sample'].iloc[5,:]['Annualized Volatility']:.1f}%\", horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .83, f\"IR={res['out-of-sample'].iloc[5,:]['Information Ratio']:.2f}\",         horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "fig.savefig(\"plots/model6_nonlinear_IR_wealth.pdf\")\n",
    "plt.show()\n",
    "\n",
    "res['out-of-sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['performance'  ]['period'] = 'all'\n",
    "res['in-sample'    ]['period'] = 'in-sample'\n",
    "res['out-of-sample']['period'] = 'out-of-sample'    \n",
    "r = pd.concat( [ res['performance'], res['in-sample'], res['out-of-sample'] ] )\n",
    "r['model'] = 'IR nonlinear'\n",
    "r['epochs'] = N\n",
    "r.to_csv(\"results/model6_nonlinear_IR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest the strategy actually learned\n",
    "\n",
    "r = compute_portfolio_returns( signal, np.expm1(trailing_log_returns) ) \n",
    "p = np.exp(cumsum_na(r))               # Log-price = cummulated log-returns\n",
    "p = replace_last_leading_NaN_with_1(p) # \"cumsum\" is not the exact inverse of \"diff\" -- it discards the first value, 1: put it back\n",
    "s = analyze_returns( r[ r.index > DATE1 ], as_df = True )   \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(5):\n",
    "    ax.plot( res['dates'], res['prices'].iloc[i,:], color = quintile_colours[i] )\n",
    "ax.plot( p.index, p, color='black' )\n",
    "ax.axvline( pd.to_datetime(DATE1), color='black', linewidth=1 )\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Maximizing the IR (weights)')\n",
    "ax.text(0.02, .97, f\"μ={100*s.iloc[0,:]['CAGR']:.1f}%\",                  horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .90, f\"σ={100*s.iloc[0,:]['Annualized Volatility']:.1f}%\", horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "ax.text(0.02, .83, f\"IR={s.iloc[0,:]['Information Ratio']:.2f}\",         horizontalalignment='left', verticalalignment='top', transform = ax.transAxes)\n",
    "fig.savefig(\"plots/model6_nonlinear_IR_wealth_weights.pdf\")\n",
    "plt.show()\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['period'] = 'out-of-sample'    \n",
    "s['model'] = 'IR nonlinear'\n",
    "s['portfolio'] = 'Weights'\n",
    "s['epochs'] = N\n",
    "s.to_csv(\"results/model6_nonlinear_IR_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to understand what the model actually learned\n",
    "\n",
    "def plot_copula(x,y, ax=None, title=None, unif=True, cmap='Blues'):\n",
    "    i = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[i]\n",
    "    y = y[i]\n",
    "\n",
    "    if unif:\n",
    "        x = uniformize(x)\n",
    "        y = uniformize(y)\n",
    "        xmin, xmax, ymin, ymax = 0,1, 0,1\n",
    "    else:\n",
    "        xmin, xmax = min(x), max(x)\n",
    "        ymin, ymax = min(y), max(y)\n",
    "\n",
    "    ax_was_None = ax is None\n",
    "    if ax_was_None:\n",
    "        fig, ax = plt.subplots( figsize = (4,4) )\n",
    "\n",
    "    xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    values = np.vstack([x,y])\n",
    "    kernel = scipy.stats.gaussian_kde(values)\n",
    "    f = np.reshape( kernel(positions).T, xx.shape )\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    cfset = ax.contourf(xx, yy, f, cmap=cmap)\n",
    "    cset = ax.contour(xx, yy, f, colors='k')\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    if ax_was_None:\n",
    "        plt.show()\n",
    "        \n",
    "def remove_empty_axes(axs):\n",
    "    for ax in axs.flatten():\n",
    "        if (not ax.lines) and (not ax.collections) and (not ax.has_data()):\n",
    "            ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Copula densities [VERY LONG: 1.5 hours]\")        \n",
    "nr, nc = mfrow(x.shape[2], aspect=1)\n",
    "fig, axs = plt.subplots( nr, nc, figsize=(29.7/1.5,21/1.5) )\n",
    "for i in tqdm(range(x.shape[2])):\n",
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    b = signal.values\n",
    "    b = np.apply_along_axis( uniformize, 0, b )    \n",
    "    ax = axs.flatten()[i]\n",
    "    plot_copula(a.flatten(),b.flatten(), ax = ax)\n",
    "    ax.set_title( predictors[i] )\n",
    "remove_empty_axes(axs)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=.2, wspace=.05)\n",
    "fig.savefig('plots/model6_nonlinear_copulas_all.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual plots\n",
    "for i in tqdm(range(x.shape[2])):\n",
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    b = signal.values\n",
    "    b = np.apply_along_axis( uniformize, 0, b )    \n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    plot_copula(a.flatten(),b.flatten(), ax = ax)\n",
    "    ax.set_title( predictors[i] )\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'plots/model6_nonlinear_copulas_{predictors[i]}.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = mfrow(x.shape[2], aspect=1)\n",
    "fig, axs = plt.subplots( nr, nc, figsize=(29.7/1.5,21/1.5) )\n",
    "for i in tqdm(range(x.shape[2])):\n",
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    \n",
    "    if False: \n",
    "      # Some of the variables just measure size: normalize them\n",
    "      # (not really possible with the data we have: we can only see something for FCF -- for most other variables, the effect of the MCap is overpowering)\n",
    "      if i > 0:\n",
    "        a = a - x.detach().numpy()[:,:,0]\n",
    "        a = np.apply_along_axis( uniformize, 0, a )    \n",
    "        \n",
    "    b = signal.values.copy()\n",
    "    a = np.floor( a * 20 * .9999 )\n",
    "    b = np.apply_along_axis( uniformize, 0, b )\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    c = pd.DataFrame( { 'quantile': a, 'value': b } )\n",
    "    c = c.pivot_table(values='value', columns = 'quantile', aggfunc='mean')\n",
    "    ax = axs.flatten()[i]\n",
    "    ax.plot( c.columns, c.values.flatten() )\n",
    "    ax.scatter( c.columns, c.values.flatten() )\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)    \n",
    "    ax.set_title( predictors[i] )\n",
    "remove_empty_axes(axs)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=.2, wspace=.05)\n",
    "fig.savefig('plots/model6_nonlinear_median_per_quantile_all.pdf')\n",
    "plt.show()\n",
    "\n",
    "LOG( \"Individual plots\" )\n",
    "for i in tqdm(range(x.shape[2])):\n",
    "   \n",
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    b = signal.values.copy()\n",
    "    a = np.floor( a * 20 * .9999 )\n",
    "    b = np.apply_along_axis( uniformize, 0, b )\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    c = pd.DataFrame( { 'quantile': a, 'value': b } )\n",
    "    c = c.pivot_table(values='value', columns = 'quantile', aggfunc='mean')\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    ax.plot( c.columns, c.values.flatten() )\n",
    "    ax.scatter( c.columns, c.values.flatten() )\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)    \n",
    "    ax.set_title( predictors[i] )\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'plots/model6_nonlinear_median_per_quantile_{predictors[i]}.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = mfrow(x.shape[2])\n",
    "fig, axs = plt.subplots( nr, nc, figsize=(20,20) )\n",
    "for i in tqdm(range(x.shape[2])):\n",
    "    ax = axs.flatten()[i]\n",
    "\n",
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    b = signal.values.copy()\n",
    "    a = np.floor( a * 20 * .9999 )\n",
    "    b = np.apply_along_axis( uniformize, 0, b )\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    c = pd.DataFrame( { 'quantile': a, 'value': b } )\n",
    "    c1 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 25))\n",
    "    c2 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 50))\n",
    "    c3 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 75))\n",
    "    c0 = c1.columns\n",
    "    c1 = c1.values.flatten()\n",
    "    c2 = c2.values.flatten()\n",
    "    c3 = c3.values.flatten()\n",
    "    ax.fill_between( c0, c1, c3, color='lightblue')\n",
    "    ax.plot(c0, c1, color='tab:blue')\n",
    "    ax.plot(c0, c3, color='tab:blue')\n",
    "    ax.plot(c0, c2, marker='o', color='black')\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)    \n",
    "    ax.set_title( predictors[i] )\n",
    "remove_empty_axes(axs)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(hspace=.2, wspace=.05)\n",
    "fig.savefig('plots/model6_nonlinear_quartiles_per_quantile_all.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "    b = signal.values.copy()\n",
    "    a = np.floor( a * 20 * .9999 )\n",
    "    b = np.apply_along_axis( uniformize, 0, b )\n",
    "    a = a.flatten()\n",
    "    b = b.flatten()\n",
    "    c = pd.DataFrame( { 'quantile': a, 'value': b } )\n",
    "    c1 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 25))\n",
    "    c2 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 50))\n",
    "    c3 = c.pivot_table(values='value', columns = 'quantile', aggfunc=lambda x: np.percentile(x, 75))\n",
    "    c0 = c1.columns\n",
    "    c1 = c1.values.flatten()\n",
    "    c2 = c2.values.flatten()\n",
    "    c3 = c3.values.flatten()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.fill_between( c0, c1, c3, color='lightblue')\n",
    "    ax.plot(c0, c1, marker='o', color='tab:blue')\n",
    "    ax.plot(c0, c3, marker='o', color='tab:blue')\n",
    "    ax.plot(c0, c2, marker='o', color='black')\n",
    "    ax.axes.xaxis.set_visible(False)\n",
    "    ax.axes.yaxis.set_visible(False)    \n",
    "    ax.set_title( predictors[i] )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for which in ['scatter', 'hexbin']:\n",
    "    LOG( which )\n",
    "    nr, nc = mfrow(x.shape[2], aspect=1)\n",
    "    fig, axs = plt.subplots( nr, nc, figsize=(29.7/1.5,21/1.5) )\n",
    "    for i in tqdm(range(x.shape[2])):\n",
    "        a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "        b = signal.values.copy()\n",
    "        b = np.apply_along_axis( uniformize, 0, b )\n",
    "        a = a.flatten()\n",
    "        b = b.flatten()\n",
    "        ax = axs.flatten()[i]\n",
    "        if which == 'scatter': \n",
    "            n = len(a)\n",
    "            ax.scatter(\n",
    "                a + .01 * np.random.uniform(-1,1,n), \n",
    "                b + .01 * np.random.uniform(-1,1,n),\n",
    "                alpha=1/255, \n",
    "                s=10\n",
    "            )\n",
    "        else: \n",
    "            ax.hexbin( a, b, gridsize=20, cmap='Blues' )\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)    \n",
    "        ax.set_title( predictors[i] )\n",
    "    remove_empty_axes(axs)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=.22, wspace=.05)\n",
    "    if which == 'scatter':\n",
    "        LOG( f\"{which}: PNG file\" )\n",
    "        fig.savefig(f'plots/model6_nonlinear_{which}_all.png', facecolor='white', transparent=False)  # The PDF file would be too large...\n",
    "    else: \n",
    "        LOG( f\"{which}: PDF file\" )\n",
    "        fig.savefig(f'plots/model6_nonlinear_{which}_all.pdf')\n",
    "    LOG( \"Plot\" )\n",
    "    plt.show()\n",
    "    \n",
    "    LOG( f\"{which}: Individual plots\" )\n",
    "    for i in tqdm(range(x.shape[2])):\n",
    "\n",
    "        a = np.where( universe[:,:,0], x[:,:,i], np.nan )\n",
    "        b = signal.values.copy()\n",
    "        b = np.apply_along_axis( uniformize, 0, b )\n",
    "        a = a.flatten()\n",
    "        b = b.flatten()\n",
    "        if which == 'scatter': \n",
    "            fig, ax = plt.subplots(figsize=(19.20,10.80))\n",
    "        else: \n",
    "            fig, ax = plt.subplots(figsize=(3,3))\n",
    "        if which == 'scatter': \n",
    "            n = len(a)\n",
    "            ax.scatter( \n",
    "                a + .01 * np.random.uniform(-1,1,n), \n",
    "                b + .01 * np.random.uniform(-1,1,n),\n",
    "                alpha=1/255, s=200\n",
    "            )\n",
    "            ax.set_xlim(0,1)\n",
    "            ax.set_ylim(0,1)            \n",
    "        else: \n",
    "            ax.hexbin( a, b, gridsize=20, cmap='Blues' )\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)    \n",
    "        ax.set_title( predictors[i] )        \n",
    "        fig.tight_layout()\n",
    "        if which == 'scatter':\n",
    "            fig.savefig(f'plots/model6_nonlinear_{which}_{predictors[i]}.png', facecolor='white', transparent = False)\n",
    "        else:\n",
    "            fig.savefig(f'plots/model6_nonlinear_{which}_{predictors[i]}.pdf')\n",
    "        plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG( \"Done.\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
